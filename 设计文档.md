## 设计文档：备盘池功能开发
## 代码实现部分：
1. 添加Volume.py文件，实现VolumeWorker类。主要是周期性执行的任务的注册；主要的函数包括备盘和同步：
2. 启动VolumeWorker类，与api、worker、controller的启动方式一样，放在__main__.py中，通过传入的参数--module=volumePool来指定。

- 周期性备盘：根据配置文件中的参数来执行操作。
    - def backup_volumes()
    - step1: 身份认证，获取token，tenant id
    - step2：从配置文件中获取备盘的配置信息.这里我们根据type(igw,bgw,dhcp,cast)来创建不同的盘。移植到cube的话，变成不同的系统debian, windows等等
    - step3: 检查数据库，看这次备盘操作 哪几种类型的盘需要备，需要备多少个。用两个参数来过滤计数(snapshot_type, status)
    - step4：create_volume(cld_api, vol_data), 通过post请求Cinder API，创盘
    - step5: 将创盘的记录加入到数据库中
      - 根据返回值中的volume_id，查询数据库是否有条目
      - 如果有，就更新相关的信息。name, status, allocated
      - 如果没有，创建一条新的条目。id, name, type, snapshot, allocated

- 周期性同步：用于本地数据库与远程openstack进行信息同步。本地维护一份备盘池备份的信息。
    - def sync_volume_db()
    - step1: 身份认证，获取token，tenant id
    - step2：获取数据库中所有的volume_ids
    - step3: 利用_get_volume_by_id(),向cinder发送GET请求查询volume的状态。如果不同，就修改本地数据库，更新数据库表中的各个属性，这里只检查status和name，status可能从creating变为available(数据库中只保留status=available或者status=creating的条目)。如果不存在或者创建异常或者in-use，**就删除条目**。


## 数据库部分：
添加了数据库相关的表以及sql。主要修改'model.py'，添加sql创表。序富把这部分工作做好了。

| 属性       | 含义                                                     | 备注 |
| ---------- | -------------------------------------------------------- | ---- |
| id         | 自增ID                                                   |      |
| volume_id  | volume的UUID，与cinder中的volume id相同                  | key  |
| name       | volume的name                                             | string     |
| type       | volume的type类型                                         | string     |
| snapshot   | volume的snapshot name                                    | int     |
| allocated  | 是否已经被分配了                                         | bool |
| status     | available, creating, error...                           |  string    |
| created_at | 创建时间                                                 |   string   |
| updated_at | 更新时间                                                 |  string    |

- status的变化。只能在同步的时候进行修改。刚开始插入的时候应该都是creating。
- 统计某个备盘的数量的时候，根据不同的snapshot来分类统计。
- allocated这个字段不需要了

## 配置文件内容新增:
暂时想到的，后续可能会添加[vollume_pool]
  - 需要备盘的snapshot_ids。一个列表，可以储存多对[snapshot_type -> snapshot_id]
  - 需要备盘的数量。一个列表，可以储存多对[snapshot_type -> nums]
  - project_code, user_code, admin_code。用于身份验证，OS_API.get_new_cld_token
  - 备盘的周期频率
  - 同步的周期频率

## 原来流程修改
创建vnfp：
查询数据库获取可用的`volume list`[从数据库中取, status=available]，创建vnfp的时候可以选择list中其中之一。
主要修改`create_volume()`。创盘或者从备盘池中选择，用户无感知。
分析原来的流程：
- step1: 从传入参数中获取vnf_type
- step2: 根据type获取snapshot_id.(向openstack查询，以命名开头为选择的依据)
- step3: 从参数中获取db_vol_ids。然后用一层for循环来逐个遍历。
  - 如果vol_id为空，**创建新的盘**，并为vol_id赋值。
  - 如果vol_id非空，检查volume的状态。
    - 如果status为error，删盘，再 **创建新的盘**
    - 否则，不做任何操作。

我们的工作主要是在创盘阶段，增加一段代码逻辑。先从备盘池中根据type去查询是否有多余的盘(status='available', type=vnf_type)。
- 如果有多余的盘，直接为vol_id赋值，然后rename这个盘，**然后我们把这条记录从备盘池的数据库中删掉。**
- 如果没有多余的盘，采用原来的方案，调用_create_volume()，创盘。


## beat、crontab实现周期性任务
```python
## 方式1： 利用send_periodic_task
sender.add_periodic_task(10.0, test.s('hello'), name='add every 10')
## 方式2： 用配置文件的方式
app.conf.beat_schedule = {
    'add-every-30-seconds': {
        'task': 'tasks.add',
        'schedule': 30.0,
        'args': (16, 16)
    },
}
app.conf.timezone = 'UTC'
## crontab可以控制的时间更加精细。
class celery.schedules.crontab(minute=u'*', hour=u'*', day_of_week=u'*', day_of_month=u'*', month_of_year=u'*', **kwargs)
```

参考的文档：
http://docs.celeryproject.org/en/latest/userguide/periodic-tasks.html
http://docs.celeryproject.org/en/latest/reference/celery.schedules.html#celery.schedules.crontab

## 问题
1. 在运行周期任务的时候，beat需要独立出来跑，持续监听。
如果一般我们跑定时任务的时候通过两个命令
```
celery worker -A periodic_task
celery beat -A periodic_task
```
**在比较大的工程里面如何将beat独立出来呢？有没有什么比较好的解决方案？**

原来的方案设计的不足在于备盘池的创建、使用与vnfp的生命周期绑定，数据库中用allocated字段来记录备盘池中volume的使用状态，让代码处理逻辑变得复杂，我们在创建、删除、更新vnfp的时候还要增加处理备盘池的逻辑。
经大家的建议，可以尝试参照设计模式中的单一职责原则，让备盘池的进程只完成一个职责——只需要保持备盘池有足够的盘即可。将这个过程与vnfp的生命周期分隔开。

针对上一个方案的修改：
1. 不再需要数据库中字段allocated。
2. 我们备盘池与vnfp交互主要是在创盘阶段`create_volume()`，增加一段代码逻辑。先从备盘池中根据type去查询是否有多余的盘(status='available', type=vnf_type)。
  - 如果备盘池中有多余的盘，直接为vol_id赋值，**然后我们把这条记录从备盘池的数据库中删掉。**(解释：当备盘池中的盘被使用后，我们从备盘池中移除。待周期性备盘操作执行的时候再向备盘池中补充)
  - 如果没有多余的盘，采用原来的方案，调用_create_volume()，创盘。
3. 在我们进行同步操作的时候，检查本地与openstack的volume状态是否一致。**并且将status不正常的volume记录从数据库中删除**。保证数据库中存储的始终是备盘池中有效可用的volume。
